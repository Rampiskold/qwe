"""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Agent Visualizer API –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º.

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É —Å –ø–∞—Ä—Å–µ—Ä–æ–º –ª–æ–≥–æ–≤ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞–º–∏
–±–µ–∑ –∑–∞–ø—É—Å–∫–∞ Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.
"""

import json
from pathlib import Path
from log_parser import LogParser
from visualizers import RoadmapVisualizer, MetricsVisualizer, TimelineVisualizer


def load_log_example(log_file_path: str) -> None:
    """
    –ü—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤.
    
    Args:
        log_file_path: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å –ª–æ–≥–∞–º–∏
    """
    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–≥–æ–≤ –∏–∑: {log_file_path}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º JSON
    with open(log_file_path, 'r', encoding='utf-8') as f:
        log_data = json.load(f)
    
    print(f"‚úÖ –õ–æ–≥–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    print(f"   ID –∞–≥–µ–Ω—Ç–∞: {log_data.get('id', 'N/A')}")
    print(f"   –ó–∞–¥–∞—á–∞: {log_data.get('task', 'N/A')}")
    print(f"   –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: {', '.join(log_data.get('toolkit', []))}")
    print()
    
    return log_data


def analyze_steps(parser: LogParser) -> None:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —à–∞–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞.
    
    Args:
        parser: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –ª–æ–≥–æ–≤
    """
    print("üîç –ê–Ω–∞–ª–∏–∑ —à–∞–≥–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
    print("=" * 60)
    
    steps = parser.get_steps()
    print(f"–í—Å–µ–≥–æ —à–∞–≥–æ–≤: {len(steps)}\n")
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º
    step_types = {}
    for step in steps:
        step_types[step.step_type] = step_types.get(step.step_type, 0) + 1
    
    print("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:")
    for step_type, count in step_types.items():
        print(f"  - {step_type}: {count}")
    print()
    
    # –î–µ—Ç–∞–ª–∏ –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —à–∞–≥–æ–≤
    print("–ü–µ—Ä–≤—ã–µ 3 —à–∞–≥–∞:")
    for step in steps[:3]:
        print(f"\n  –®–∞–≥ {step.step_number}: {step.step_type}")
        print(f"    –§–∞–∑–∞: {step.phase or 'N/A'}")
        if step.metrics:
            print(f"    –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {step.metrics.get('duration_ms', 'N/A')} –º—Å")
            print(f"    –¢–æ–∫–µ–Ω—ã: {step.metrics.get('total_tokens', 'N/A')}")
        if step.reasoning and step.reasoning.get('current_situation'):
            situation = step.reasoning['current_situation'][:80]
            print(f"    –°–∏—Ç—É–∞—Ü–∏—è: {situation}...")
    print()


def analyze_metrics(parser: LogParser) -> None:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
    
    Args:
        parser: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –ª–æ–≥–æ–≤
    """
    print("üìä –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    print("=" * 60)
    
    metrics = parser.get_aggregated_metrics()
    
    print(f"–í—Å–µ–≥–æ —à–∞–≥–æ–≤: {metrics['total_steps']}")
    print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è: {metrics['total_duration_ms']:.2f} –º—Å ({metrics['total_duration_ms']/1000:.2f} —Å–µ–∫)")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —à–∞–≥: {metrics['avg_duration_per_step']:.2f} –º—Å")
    print()
    
    print(f"–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {metrics['total_tokens']}")
    print(f"  - Prompt —Ç–æ–∫–µ–Ω—ã: {metrics['total_prompt_tokens']}")
    print(f"  - Completion —Ç–æ–∫–µ–Ω—ã: {metrics['total_completion_tokens']}")
    print(f"–°—Ä–µ–¥–Ω–µ–µ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ LLM –≤—ã–∑–æ–≤: {metrics['avg_tokens_per_llm_call']:.2f}")
    print()
    
    print(f"LLM –≤—ã–∑–æ–≤–æ–≤: {metrics['llm_calls']}")
    print(f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: {metrics['tool_executions']}")
    print()


def analyze_tool_usage(parser: LogParser) -> None:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
    
    Args:
        parser: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –ª–æ–≥–æ–≤
    """
    print("üõ†Ô∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
    print("=" * 60)
    
    tool_stats = parser.get_tool_usage_stats()
    
    if not tool_stats:
        print("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å")
        return
    
    print(f"–í—Å–µ–≥–æ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: {sum(tool_stats.values())}")
    print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º:")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π
    sorted_tools = sorted(tool_stats.items(), key=lambda x: x[1], reverse=True)
    
    for tool_name, count in sorted_tools:
        percentage = (count / sum(tool_stats.values())) * 100
        print(f"  - {tool_name}: {count} ({percentage:.1f}%)")
    print()


def analyze_reasoning_evolution(parser: LogParser) -> None:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–≤–æ–ª—é—Ü–∏—é reasoning –∞–≥–µ–Ω—Ç–∞.
    
    Args:
        parser: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –ª–æ–≥–æ–≤
    """
    print("üß† –≠–≤–æ–ª—é—Ü–∏—è reasoning")
    print("=" * 60)
    
    evolution = parser.get_reasoning_evolution()
    
    if not evolution:
        print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ reasoning")
        return
    
    print(f"–í—Å–µ–≥–æ reasoning —à–∞–≥–æ–≤: {len(evolution)}\n")
    
    for idx, item in enumerate(evolution, 1):
        print(f"Reasoning —à–∞–≥ {idx} (–æ–±—â–∏–π —à–∞–≥ {item['step_number']}):")
        print(f"  –°–∏—Ç—É–∞—Ü–∏—è: {item['current_situation'][:80]}...")
        print(f"  –ü–ª–∞–Ω: {item['plan_status']}")
        print(f"  –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {'‚úÖ –î–∞' if item['enough_data'] else '‚ùå –ù–µ—Ç'}")
        print(f"  –ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {'‚úÖ –î–∞' if item['task_completed'] else '‚è≥ –í –ø—Ä–æ—Ü–µ—Å—Å–µ'}")
        
        if item['remaining_steps']:
            print(f"  –û—Å—Ç–∞–≤—à–∏–µ—Å—è —à–∞–≥–∏ ({len(item['remaining_steps'])}):")
            for step in item['remaining_steps'][:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2
                print(f"    - {step}")
        print()


def save_visualizations(parser: LogParser, output_dir: str = "output") -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ HTML —Ñ–∞–π–ª—ã.
    
    Args:
        parser: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –ª–æ–≥–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
    """
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    steps = parser.get_steps()
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
    roadmap_viz = RoadmapVisualizer()
    metrics_viz = MetricsVisualizer()
    timeline_viz = TimelineVisualizer()
    
    # –†–æ—É–¥–º–∞–ø
    print("  –°–æ–∑–¥–∞–Ω–∏–µ —Ä–æ—É–¥–º–∞–ø–∞...")
    fig_roadmap = roadmap_viz.create_roadmap(steps)
    fig_roadmap.write_html(output_path / "roadmap.html")
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    print("  –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –º–µ—Ç—Ä–∏–∫...")
    fig_duration = metrics_viz.create_duration_chart(steps)
    fig_duration.write_html(output_path / "duration.html")
    
    fig_tokens = metrics_viz.create_tokens_chart(steps)
    fig_tokens.write_html(output_path / "tokens.html")
    
    fig_cumulative = metrics_viz.create_cumulative_timeline(steps)
    fig_cumulative.write_html(output_path / "cumulative.html")
    
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    tool_stats = parser.get_tool_usage_stats()
    if tool_stats:
        fig_tools = metrics_viz.create_tool_usage_pie(tool_stats)
        fig_tools.write_html(output_path / "tool_usage.html")
    
    # –í—Ä–µ–º–µ–Ω–Ω–∞—è –ª–∏–Ω–∏—è
    print("  –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏...")
    fig_timeline = timeline_viz.create_timeline(steps)
    fig_timeline.write_html(output_path / "timeline.html")
    
    print(f"\n‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {output_path.absolute()}")
    print(f"   –û—Ç–∫—Ä—ã—Ç—å —Ä–æ—É–¥–º–∞–ø: file://{output_path.absolute()}/roadmap.html")
    print()


def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–º–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
    
    –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã —Å –ª–æ–≥–∞–º–∏ –∞–≥–µ–Ω—Ç–∞:
    –∑–∞–≥—Ä—É–∑–∫–∞, –ø–∞—Ä—Å–∏–Ω–≥, –∞–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è.
    """
    print("=" * 60)
    print("ü§ñ SGR Agent Visualizer - –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API")
    print("=" * 60)
    print()
    
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–æ–≤ (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π)
    log_file = "../logs/20251217-070215-russian_deep_research_agent_43092779-2eaa-439d-ba74-8f6eca97b211-log.json"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if not Path(log_file).exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {log_file}")
        print("\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  python example_usage.py")
        print("\n–ò–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É —Ñ–∞–π–ª—É –≤ –∫–æ–¥–µ.")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–æ–≥–∏
    log_data = load_log_example(log_file)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = LogParser(log_data)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∏–¥—ã –∞–Ω–∞–ª–∏–∑–∞
    analyze_steps(parser)
    analyze_metrics(parser)
    analyze_tool_usage(parser)
    analyze_reasoning_evolution(parser)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    save_visualizations(parser, output_dir="output")
    
    print("=" * 60)
    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print("=" * 60)


if __name__ == "__main__":
    main()

