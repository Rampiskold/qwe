"""
–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç—Ä–µ–π—Å–∏–Ω–≥–∞ –∞–≥–µ–Ω—Ç–∞.

–ú–æ–¥—É–ª—å —Å–æ–∑–¥–∞–µ—Ç —Ä–æ—É–¥–º–∞–ø —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ JSON –ª–æ–≥–æ–≤,
—á—Ç–æ–±—ã –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å —à–∞–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, reasoning, –≤—ã–∑–æ–≤—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏ –º–µ—Ç—Ä–∏–∫–∏.
"""

import streamlit as st
import json
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
from log_parser import LogParser, AgentStep
from visualizers import RoadmapVisualizer, MetricsVisualizer, TimelineVisualizer
from trace_visualizer import TraceVisualizer
import json


def load_log_file(file_path: str) -> Optional[Dict[str, Any]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏ –∞–≥–µ–Ω—Ç–∞.
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ª–æ–≥–∞–º–∏
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ª–æ–≥–æ–≤ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
        return None


def get_available_logs(logs_dir: str = "logs") -> List[Path]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    
    Args:
        logs_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –ª–æ–≥–∞–º–∏
        
    Returns:
        –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –ª–æ–≥–æ–≤
    """
    logs_path = Path(logs_dir)
    if not logs_path.exists():
        return []
    
    return sorted(
        logs_path.glob("*.json"),
        key=lambda x: x.stat().st_mtime,
        reverse=True
    )


def render_agent_info(log_data: Dict[str, Any]) -> None:
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–≥–µ–Ω—Ç–µ –∏ –∑–∞–¥–∞—á–µ.
    
    Args:
        log_data: –î–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤
    """
    st.header("ü§ñ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≥–µ–Ω—Ç–µ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ID –∞–≥–µ–Ω—Ç–∞", log_data.get('id', 'N/A').split('_')[-1][:8])
        st.metric("–ú–æ–¥–µ–ª—å", log_data.get('model_config', {}).get('model', 'N/A'))
    
    with col2:
        st.metric("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", log_data.get('model_config', {}).get('temperature', 'N/A'))
        st.metric("Max tokens", log_data.get('model_config', {}).get('max_tokens', 'N/A'))
    
    with col3:
        toolkit = log_data.get('toolkit', [])
        st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤", len(toolkit))
        
    st.subheader("üìã –ó–∞–¥–∞—á–∞")
    st.info(log_data.get('task', '–ó–∞–¥–∞—á–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'))
    
    st.subheader("üõ†Ô∏è –ù–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
    cols = st.columns(4)
    for idx, tool in enumerate(toolkit):
        with cols[idx % 4]:
            st.code(tool, language=None)


def render_roadmap(parser: LogParser, visualizer: RoadmapVisualizer) -> None:
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–æ—É–¥–º–∞–ø —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞.
    
    Args:
        parser: –ü–∞—Ä—Å–µ—Ä –ª–æ–≥–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        visualizer: –í–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–æ—É–¥–º–∞–ø–∞
    """
    st.header("üó∫Ô∏è –†–æ—É–¥–º–∞–ø –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
    
    steps = parser.get_steps()
    
    if not steps:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–æ—É–¥–º–∞–ø–∞")
        return
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–æ—É–¥–º–∞–ø–∞
    fig = visualizer.create_roadmap(steps)
    st.plotly_chart(fig, width='stretch')
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞ - –≥—Ä—É–ø–ø–∏—Ä—É–µ–º reasoning –∏ execution
    st.subheader("üìù –î–µ—Ç–∞–ª–∏ —à–∞–≥–æ–≤")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —à–∞–≥–∏ –ø–æ –Ω–æ–º–µ—Ä—É
    steps_grouped = {}
    for step in steps:
        if step.step_number not in steps_grouped:
            steps_grouped[step.step_number] = []
        steps_grouped[step.step_number].append(step)
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —à–∞–≥–∏
    for step_num in sorted(steps_grouped.keys()):
        render_step_group(step_num, steps_grouped[step_num])


def render_step_group(step_num: int, steps: List[AgentStep]) -> None:
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –≥—Ä—É–ø–ø—É —à–∞–≥–æ–≤ —Å –æ–¥–Ω–∏–º –Ω–æ–º–µ—Ä–æ–º (reasoning + execution).
    
    Args:
        step_num: –ù–æ–º–µ—Ä —à–∞–≥–∞
        steps: –°–ø–∏—Å–æ–∫ —à–∞–≥–æ–≤ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –Ω–æ–º–µ—Ä–æ–º
    """
    # –ù–∞—Ö–æ–¥–∏–º reasoning –∏ execution —à–∞–≥–∏
    reasoning_step = None
    execution_steps = []
    llm_calls = []
    
    for step in steps:
        if step.step_type == 'reasoning':
            reasoning_step = step
        elif step.step_type == 'tool_execution':
            execution_steps.append(step)
        elif step.step_type == 'llm_call':
            llm_calls.append(step)
    
    # –°—á–∏—Ç–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø–µ—Ä–∞—Ü–∏–π
    total_ops = len([s for s in steps if s.step_type in ['reasoning', 'tool_execution']])
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç –∏ –∏–∫–æ–Ω–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ —à–∞–≥–∞
    if reasoning_step and reasoning_step.reasoning.get('task_completed'):
        icon = "‚úÖ"
        color = "green"
    elif execution_steps:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        tool_names = [e.tool_calls[0]['name'] if e.tool_calls else 'unknown' for e in execution_steps]
        if 'finalanswertool' in tool_names:
            icon = "‚úÖ"
        else:
            icon = "üõ†Ô∏è"
        color = "blue"
    else:
        icon = "ü§î"
        color = "orange"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —à–∞–≥–∞
    step_desc = []
    if reasoning_step:
        step_desc.append("reasoning")
    if execution_steps:
        for exec_step in execution_steps:
            if exec_step.tool_calls:
                tool_name = exec_step.tool_calls[0].get('name', 'unknown')
                step_desc.append(tool_name)
    
    desc_text = " + ".join(step_desc) if step_desc else f"{len(steps)} –æ–ø–µ—Ä–∞—Ü–∏–π"
    
    with st.expander(f"{icon} **–®–∞–≥ {step_num}** - {desc_text}", expanded=False):
        
        # Reasoning –±–ª–æ–∫
        if reasoning_step:
            st.markdown("### üß† Reasoning")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                if reasoning_step.reasoning.get('current_situation'):
                    st.info(f"**–°–∏—Ç—É–∞—Ü–∏—è:** {reasoning_step.reasoning['current_situation']}")
                
                if reasoning_step.reasoning.get('plan_status'):
                    st.write(f"**–ü–ª–∞–Ω:** {reasoning_step.reasoning['plan_status']}")
            
            with col2:
                col_status1, col_status2 = st.columns(2)
                with col_status1:
                    if 'enough_data' in reasoning_step.reasoning:
                        status = "‚úÖ" if reasoning_step.reasoning['enough_data'] else "‚ùå"
                        st.metric("–î–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ", status)
                with col_status2:
                    if 'task_completed' in reasoning_step.reasoning:
                        status = "‚úÖ" if reasoning_step.reasoning['task_completed'] else "‚è≥"
                        st.metric("–ó–∞–¥–∞—á–∞", status)
            
            # –®–∞–≥–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
            if reasoning_step.reasoning.get('reasoning_steps'):
                st.markdown("**üí≠ –®–∞–≥–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è:**")
                for idx, r_step in enumerate(reasoning_step.reasoning['reasoning_steps'], 1):
                    st.markdown(f"{idx}. {r_step}")
            
            # –û—Å—Ç–∞–≤—à–∏–µ—Å—è —à–∞–≥–∏
            if reasoning_step.reasoning.get('remaining_steps'):
                st.markdown("**üìã –ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:**")
                for r_step in reasoning_step.reasoning['remaining_steps']:
                    st.markdown(f"- {r_step}")
            
            st.divider()
        
        # LLM Calls –±–ª–æ–∫
        if llm_calls:
            st.markdown("### ü§ñ LLM –≤—ã–∑–æ–≤—ã")
            
            for llm_step in llm_calls:
                with st.container():
                    col1, col2, col3 = st.columns([2, 1, 1])
                    
                    with col1:
                        phase_emoji = {"reasoning_phase": "üß†", "action_selection": "üéØ", "execution": "‚ö°"}.get(llm_step.phase, "üìû")
                        st.write(f"{phase_emoji} **–§–∞–∑–∞:** {llm_step.phase or 'N/A'}")
                    
                    with col2:
                        if 'duration_ms' in llm_step.metrics:
                            st.metric("‚è±Ô∏è –í—Ä–µ–º—è", f"{llm_step.metrics['duration_ms']:.0f} –º—Å")
                    
                    with col3:
                        if 'total_tokens' in llm_step.metrics:
                            st.metric("üé´ –¢–æ–∫–µ–Ω—ã", llm_step.metrics['total_tokens'])
                    
                    # Tool calls –∏–∑ LLM –æ—Ç–≤–µ—Ç–∞
                    if llm_step.tool_calls:
                        st.markdown("**–ó–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:**")
                        for tool_call in llm_step.tool_calls:
                            st.code(f"üìû {tool_call['name']}", language=None)
            
            st.divider()
        
        # Tool Execution –±–ª–æ–∫
        if execution_steps:
            st.markdown("### üõ†Ô∏è –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
            
            for exec_step in execution_steps:
                with st.container():
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        if exec_step.tool_calls:
                            for tool_call in exec_step.tool_calls:
                                tool_name = tool_call.get('name', 'unknown')
                                tool_emoji = {
                                    'websearchtool': 'üîç',
                                    'extractpagecontenttool': 'üìÑ',
                                    'finalanswertool': '‚úÖ',
                                    'reasoningtool': 'üß†'
                                }.get(tool_name, 'üîß')
                                
                                st.markdown(f"**{tool_emoji} {tool_name}**")
                                
                                # –ê—Ä–≥—É–º–µ–Ω—Ç—ã
                                args = tool_call.get('arguments', {})
                                if args:
                                    with st.expander("–ê—Ä–≥—É–º–µ–Ω—Ç—ã", expanded=False):
                                        st.json(args)
                    
                    with col2:
                        if 'duration_ms' in exec_step.metrics:
                            st.metric("‚è±Ô∏è –í—Ä–µ–º—è", f"{exec_step.metrics['duration_ms']:.0f} –º—Å")
                    
                    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
                    if exec_step.search_results:
                        st.markdown(f"**üîç –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(exec_step.search_results)}**")
                        
                        with st.expander(f"–ü–æ–∫–∞–∑–∞—Ç—å {len(exec_step.search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", expanded=False):
                            for idx, result in enumerate(exec_step.search_results, 1):
                                st.markdown(f"**{idx}. {result.get('title', 'N/A')}**")
                                st.markdown(f"üîó [{result.get('url', 'N/A')}]({result.get('url', '#')})")
                                if result.get('content'):
                                    st.caption(result['content'][:150] + "...")
                                st.divider()
                    
                    st.markdown("---")


def render_metrics(parser: LogParser, metrics_viz: MetricsVisualizer) -> None:
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞.
    
    Args:
        parser: –ü–∞—Ä—Å–µ—Ä –ª–æ–≥–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        metrics_viz: –í–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫
    """
    st.header("üìä –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    
    metrics = parser.get_aggregated_metrics()
    
    if not metrics:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –º–µ—Ç—Ä–∏–∫–∞—Ö")
        return
    
    # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("–í—Å–µ–≥–æ —à–∞–≥–æ–≤", metrics['total_steps'])
    
    with col2:
        st.metric("–û–±—â–µ–µ –≤—Ä–µ–º—è (–º—Å)", f"{metrics['total_duration_ms']:.2f}")
    
    with col3:
        st.metric("–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤", metrics['total_tokens'])
    
    with col4:
        st.metric("LLM –≤—ã–∑–æ–≤–æ–≤", metrics['llm_calls'])
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
    tab1, tab2, tab3 = st.tabs(["‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", "üé´ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤", "üìà –î–∏–Ω–∞–º–∏–∫–∞"])
    
    with tab1:
        fig_duration = metrics_viz.create_duration_chart(parser.get_steps())
        st.plotly_chart(fig_duration, width='stretch')
    
    with tab2:
        fig_tokens = metrics_viz.create_tokens_chart(parser.get_steps())
        st.plotly_chart(fig_tokens, width='stretch')
    
    with tab3:
        fig_timeline = metrics_viz.create_cumulative_timeline(parser.get_steps())
        st.plotly_chart(fig_timeline, width='stretch')


def render_simple_trace(log_data: Dict[str, Any]) -> None:
    """
    –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç—Ä–µ–π—Å–∏–Ω–≥–∞ —Å –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∏–µ—Ä–∞—Ä—Ö–∏–µ–π (–ª–µ—Å–µ–Ω–∫–æ–π).
    
    Args:
        log_data: –î–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤
    """
    log_entries = log_data.get('log', [])
    
    if not log_entries:
        st.warning("–ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ –ª–æ–≥–µ")
        return
    
    current_step = None
    indent_level = 0
    
    for i, entry in enumerate(log_entries, 1):
        step_num = entry.get('step_number')
        step_type = entry.get('step_type')
        phase = entry.get('phase', '')
        tool_name = entry.get('tool_name', '')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –æ—Ç—Å—Ç—É–ø–∞
        if step_num != current_step:
            current_step = step_num
            indent_level = 0
        else:
            # –í–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ —à–∞–≥–∞ - –¥–µ–ª–∞–µ–º –æ—Ç—Å—Ç—É–ø
            if step_type == 'reasoning':
                indent_level = 1
            elif step_type == 'llm_call' and phase == 'action_selection':
                indent_level = 0
            elif step_type == 'tool_execution':
                indent_level = 1
        
        # –ò–∫–æ–Ω–∫–∏
        icon = {
            'llm_call': 'ü§ñ',
            'reasoning': 'üß†',
            'tool_execution': 'üõ†Ô∏è'
        }.get(step_type, 'üìù')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
        parts = [f"Step {step_num}"]
        
        if step_type == 'llm_call':
            if phase == 'reasoning_phase':
                parts.append("LLM Reasoning")
            elif phase == 'action_selection':
                parts.append("LLM Action")
            else:
                parts.append("LLM Call")
        elif step_type == 'reasoning':
            parts.append("‚Üí Reasoning Result")
        elif step_type == 'tool_execution':
            tool_icon = {
                'websearchtool': 'üîç',
                'extractpagecontenttool': 'üìÑ',
                'finalanswertool': '‚úÖ',
                'reasoningtool': 'üí≠'
            }.get(tool_name, 'üîß')
            parts.append(f"‚Üí {tool_icon} {tool_name}")
        
        title = f"{icon} {' ¬∑ '.join(parts)}"
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
        metrics_str = ""
        if step_type == 'llm_call':
            metrics = entry.get('metrics', {})
            duration = metrics.get('duration_ms', 0)
            tokens = metrics.get('total_tokens', 0)
            if duration > 0:
                metrics_str = f" ‚è± {duration:.0f}ms"
            if tokens > 0:
                metrics_str += f" üé´ {tokens}"
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—Å—Ç—É–ø —Å –ø–æ–º–æ—â—å—é columns
        if indent_level == 0:
            # –ë–µ–∑ –æ—Ç—Å—Ç—É–ø–∞
            with st.expander(f"{title}{metrics_str}", expanded=False):
                st.json(entry)
        else:
            # –° –æ—Ç—Å—Ç—É–ø–æ–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º columns
            col1, col2 = st.columns([0.1, 0.9])
            with col1:
                st.write("")  # –ü—É—Å—Ç–∞—è –∫–æ–ª–æ–Ω–∫–∞ –¥–ª—è –æ—Ç—Å—Ç—É–ø–∞
            with col2:
                with st.expander(f"{title}{metrics_str}", expanded=False):
                    st.json(entry)


def render_raw_json(log_data: Dict[str, Any]) -> None:
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç Raw JSON –ª–æ–≥–æ–≤ –≤ —É–¥–æ–±–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
    
    Args:
        log_data: –î–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤
    """
    st.header("üìã Raw JSON - –ü–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
    
    st.markdown("""
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞ –≤ –ø–æ—Ä—è–¥–∫–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞.
    –ö–∞–∂–¥–∞—è –∑–∞–ø–∏—Å—å —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —à–∞–≥–µ.
    """)
    
    log_entries = log_data.get('log', [])
    
    if not log_entries:
        st.warning("–ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ –ª–æ–≥–µ")
        return
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —à–∞–≥–∞–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    st.subheader(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(log_entries)}")
    
    for i, entry in enumerate(log_entries, 1):
        step_num = entry.get('step_number')
        step_type = entry.get('step_type')
        phase = entry.get('phase', '')
        tool_name = entry.get('tool_name', '')
        timestamp = entry.get('timestamp', '')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        title_parts = [f"[{i}] –®–∞–≥ {step_num}"]
        
        # –ò–∫–æ–Ω–∫–∞ –ø–æ —Ç–∏–ø—É
        icon = {
            'llm_call': 'ü§ñ',
            'reasoning': 'üß†',
            'tool_execution': 'üõ†Ô∏è'
        }.get(step_type, 'üìù')
        
        title_parts.append(f"{icon} {step_type}")
        
        if phase:
            phase_emoji = {
                'reasoning_phase': 'üí≠',
                'action_selection': 'üéØ'
            }.get(phase, '')
            title_parts.append(f"{phase_emoji} {phase}")
        
        if tool_name:
            tool_emoji = {
                'websearchtool': 'üîç',
                'extractpagecontenttool': 'üìÑ',
                'finalanswertool': '‚úÖ',
                'reasoningtool': 'üß†'
            }.get(tool_name, 'üîß')
            title_parts.append(f"{tool_emoji} {tool_name}")
        
        title = " - ".join(title_parts)
        
        with st.expander(title, expanded=False):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.caption(f"‚è∞ {timestamp}")
            
            with col2:
                # –ú–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                if 'metrics' in entry:
                    metrics = entry['metrics']
                    if 'duration_ms' in metrics:
                        st.metric("‚è±Ô∏è –í—Ä–µ–º—è", f"{metrics['duration_ms']:.0f} –º—Å")
            
            # –ö–ª—é—á–µ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
            if step_type == 'reasoning':
                reasoning = entry.get('agent_reasoning', {})
                
                st.markdown("### üß† Reasoning")
                
                if reasoning.get('current_situation'):
                    st.info(reasoning['current_situation'])
                
                col_r1, col_r2 = st.columns(2)
                with col_r1:
                    st.write(f"**–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö:** {'‚úÖ' if reasoning.get('enough_data') else '‚ùå'}")
                with col_r2:
                    st.write(f"**–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞:** {'‚úÖ' if reasoning.get('task_completed') else '‚è≥'}")
                
                if reasoning.get('reasoning_steps'):
                    st.markdown("**–®–∞–≥–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è:**")
                    for idx, step in enumerate(reasoning['reasoning_steps'], 1):
                        st.markdown(f"{idx}. {step}")
                
                if reasoning.get('remaining_steps'):
                    st.markdown("**–û—Å—Ç–∞–≤—à–∏–µ—Å—è —à–∞–≥–∏:**")
                    for step in reasoning['remaining_steps']:
                        st.markdown(f"- {step}")
            
            elif step_type == 'tool_execution':
                context = entry.get('agent_tool_context', {})
                result = entry.get('agent_tool_execution_result', '')
                
                st.markdown(f"### üõ†Ô∏è {tool_name}")
                
                st.markdown("**–ö–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã–∑–æ–≤–∞:**")
                st.json(context)
                
                if tool_name == 'websearchtool':
                    st.markdown("**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:**")
                    st.text(result[:1000] + "..." if len(result) > 1000 else result)
                
                elif tool_name == 'extractpagecontenttool':
                    st.markdown("**–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:**")
                    st.text(result[:500] + "..." if len(result) > 500 else result)
                
                elif tool_name == 'finalanswertool':
                    st.markdown("**–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç:**")
                    try:
                        result_json = json.loads(result)
                        st.json(result_json)
                    except:
                        st.text(result)
            
            elif step_type == 'llm_call':
                st.markdown(f"### ü§ñ LLM Call - {phase}")
                
                if 'metrics' in entry:
                    metrics = entry['metrics']
                    col_m1, col_m2, col_m3 = st.columns(3)
                    with col_m1:
                        st.metric("‚è±Ô∏è –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", f"{metrics.get('duration_ms', 0):.0f} –º—Å")
                    with col_m2:
                        st.metric("üé´ –¢–æ–∫–µ–Ω—ã", metrics.get('total_tokens', 0))
                    with col_m3:
                        st.metric("üìä –¢–æ–∫–µ–Ω—ã/—Å–µ–∫", f"{metrics.get('tokens_per_second', 0):.1f}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º tool calls –∏–∑ –æ—Ç–≤–µ—Ç–∞
                if 'response' in entry:
                    response = entry['response']
                    if 'choices' in response:
                        for choice in response['choices']:
                            message = choice.get('message', {})
                            if 'tool_calls' in message and message['tool_calls']:
                                st.markdown("**–í—ã–∑–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:**")
                                for tool_call in message['tool_calls']:
                                    func = tool_call.get('function', {})
                                    st.markdown(f"- `{func.get('name')}`")
            
            # –ü–æ–ª–Ω—ã–π JSON –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
            with st.expander("üîç –ü–æ–ª–Ω—ã–π JSON", expanded=False):
                st.json(entry)


def render_timeline(parser: LogParser, timeline_viz: TimelineVisualizer) -> None:
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –ª–∏–Ω–∏—é –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞.
    
    Args:
        parser: –ü–∞—Ä—Å–µ—Ä –ª–æ–≥–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        timeline_viz: –í–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏
    """
    st.header("‚è≥ –í—Ä–µ–º–µ–Ω–Ω–∞—è –ª–∏–Ω–∏—è")
    
    steps = parser.get_steps()
    
    if not steps:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏")
        return
    
    fig = timeline_viz.create_timeline(steps)
    st.plotly_chart(fig, width='stretch')


def main() -> None:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Streamlit.
    
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤.
    """
    st.set_page_config(
        page_title="SGR Agent Visualizer",
        page_icon="ü§ñ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ü§ñ SGR Agent Trace Visualizer")
    st.markdown("*–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Schema-Guided Reasoning*")
    
    # Sidebar –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–∞
    st.sidebar.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –í—ã–±–æ—Ä —Å–ø–æ—Å–æ–±–∞ –∑–∞–≥—Ä—É–∑–∫–∏
    load_method = st.sidebar.radio(
        "–°–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–≥–æ–≤:",
        ["–í—ã–±—Ä–∞—Ç—å –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏", "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª"]
    )
    
    log_data = None
    
    if load_method == "–í—ã–±—Ä–∞—Ç—å –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏":
        logs_dir = st.sidebar.text_input(
            "–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –ª–æ–≥–∞–º–∏:",
            value="../logs"
        )
        
        available_logs = get_available_logs(logs_dir)
        
        if available_logs:
            selected_log = st.sidebar.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –ª–æ–≥–∞:",
                options=available_logs,
                format_func=lambda x: f"{x.name} ({datetime.fromtimestamp(x.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')})"
            )
            
            if selected_log:
                log_data = load_log_file(str(selected_log))
        else:
            st.sidebar.warning(f"–õ–æ–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {logs_dir}")
    
    else:
        uploaded_file = st.sidebar.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ JSON —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏:",
            type=['json']
        )
        
        if uploaded_file:
            try:
                log_data = json.load(uploaded_file)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
    
    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    if log_data:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
        parser = LogParser(log_data)
        roadmap_viz = RoadmapVisualizer()
        metrics_viz = MetricsVisualizer()
        timeline_viz = TimelineVisualizer()
        trace_viz = TraceVisualizer()
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        render_agent_info(log_data)
        
        st.divider()
        
        # –ü—Ä–æ—Å—Ç–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç—Ä–µ–π—Å–∏–Ω–≥–∞
        st.header("üîç Trace")
        render_simple_trace(log_data)
    
    else:
        st.info("üëà –í—ã–±–µ—Ä–∏—Ç–µ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        with st.expander("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–æ—Ä–º–∞—Ç–µ –ª–æ–≥–æ–≤"):
            st.markdown("""
            –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON —Ñ–∞–π–ª–∞ —Å –ª–æ–≥–∞–º–∏:
            
            ```json
            {
                "id": "agent_id",
                "model_config": {
                    "model": "model_name",
                    "temperature": 0.2,
                    "max_tokens": 8000
                },
                "task": "–û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏",
                "toolkit": ["tool1", "tool2"],
                "log": [
                    {
                        "step_number": 1,
                        "timestamp": "2025-12-17T07:02:00.240803",
                        "step_type": "llm_call",
                        "phase": "reasoning_phase",
                        ...
                    }
                ]
            }
            ```
            """)


if __name__ == "__main__":
    main()

